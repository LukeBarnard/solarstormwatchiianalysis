{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: AstropyDeprecationWarning: Config parameter 'name_resolve_timeout' in section [coordinates.name_resolve] of the file 'C:\\Users\\Luke\\.astropy\\config\\astropy.cfg' is deprecated. Use 'remote_timeout' in section [utils.data] instead. [astropy.config.configuration]\n",
      "WARNING:astropy:AstropyDeprecationWarning: Config parameter 'name_resolve_timeout' in section [coordinates.name_resolve] of the file 'C:\\Users\\Luke\\.astropy\\config\\astropy.cfg' is deprecated. Use 'remote_timeout' in section [utils.data] instead.\n",
      "WARNING: AstropyDeprecationWarning: Config parameter 'remote_timeout' in section [utils.data] of the file 'C:\\Users\\Luke\\.astropy\\config\\astropy.cfg' is given by more than one alias (astropy.utils.data.remote_timeout, coordinates.name_resolve.name_resolve_timeout). Using the first. [astropy.config.configuration]\n",
      "WARNING:astropy:AstropyDeprecationWarning: Config parameter 'remote_timeout' in section [utils.data] of the file 'C:\\Users\\Luke\\.astropy\\config\\astropy.cfg' is given by more than one alias (astropy.utils.data.remote_timeout, coordinates.name_resolve.name_resolve_timeout). Using the first.\n",
      "C:\\Users\\Luke\\Anaconda2\\lib\\site-packages\\glymur\\lib\\config.py:151: UserWarning: Neither the openjp2 nor the openjpeg library could be loaded.  \n",
      "  warnings.warn(msg)\n",
      "WARNING:py.warnings:C:\\Users\\Luke\\Anaconda2\\lib\\site-packages\\skimage\\filter\\__init__.py:6: skimage_deprecation: The `skimage.filter` module has been renamed to `skimage.filters`.  This placeholder module will be removed in v0.13.\n",
      "  warn(skimage_deprecation('The `skimage.filter` module has been renamed '\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import tables\n",
    "import astropy.units as u\n",
    "import hi_processing.images as hip\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import simplejson as json\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from skimage import measure\n",
    "import SolarStormwatchIIAnalysis as ssw2\n",
    "import moviepy.editor as mpy\n",
    "import palettable.colorbrewer.qualitative as cmap\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "colors = cmap.Paired_12.mpl_colors\n",
    "mksz = 8\n",
    "# Get some colors to use for the different time-elongation profile sources and speed estimate methods.\n",
    "# t-e profile sources:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def make_ogv(src, dst, tidy=True):\n",
    "    file_list = glob.glob(src)\n",
    "    clip = mpy.ImageSequenceClip(file_list, fps=1)\n",
    "    clip.write_videofile(dst, audio=False, ffmpeg_params=['-qscale','6'])\n",
    "    if tidy:\n",
    "        for f in file_list:\n",
    "            os.remove(f)\n",
    "            \n",
    "def get_fwhm(x, pdf):\n",
    "    \"\"\"\n",
    "    Function to calculate the full width at half maximum of a 1-d distribution.\n",
    "    :param x:\n",
    "    :param pdf:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    #Calc FWHM\n",
    "    pdf_max = pdf.max()\n",
    "    pdf_hm = pdf_max/2.0\n",
    "    id_max = np.argwhere(pdf==pdf_max).ravel()\n",
    "    if len(id_max)>1:\n",
    "        id_max = id_max[0]\n",
    "    x_max = x[id_max]\n",
    "\n",
    "    # Look low.\n",
    "    pdf_l = pdf[x<x_max]\n",
    "    x_l = x[x<x_max]\n",
    "    if len(x_l)>1:\n",
    "        x_hm_l = x_l[np.argmin(np.abs(pdf_l - pdf_hm))]\n",
    "    else:\n",
    "        x_hm_l = np.NaN\n",
    "\n",
    "    # Look high.\n",
    "    pdf_h = pdf[x>x_max]\n",
    "    x_h = x[x>x_max]\n",
    "    if len(x_h)>1:\n",
    "        x_hm_h = x_h[np.argmin(np.abs(pdf_h - pdf_hm))]\n",
    "    else:\n",
    "        x_hm_h = np.NaN\n",
    "\n",
    "    return x_hm_l, x_max, x_hm_h\n",
    "\n",
    "\n",
    "def extract_cme_front_example(pix_coords, hpr_coords, hi_map, kernel=\"epanechnikov\", bandwidth=40, thresh=10):\n",
    "    \"\"\"\n",
    "    A function that uses Kernel density estimation and skeletonization to estimate the CME front location from the\n",
    "    cloud of classifications for this asset.\n",
    "    :param pix_coords: Dataframe of classification coordinates, with columns 'x', and 'y' for the x pixels and y pixels.\n",
    "    :param hpr_coords: Dataframe of classification coordinates, with columns 'pa', and 'el' for the pixel coords in HPR.\n",
    "    :param hi_map: A sunpy map of the HI image current being analysed.\n",
    "    :param kernel: String name of any valid kernal in scikit-learn.neighbours.KernalDensity.\n",
    "    :param bandwidth: Float value of the bandwidth to be used by the kernal. Defaults to 40 pixels, as this is\n",
    "                      approximately the error in classifications if made using a touchscreen.\n",
    "    :param thresh: Float value of threshold to apply to the density map to identify the CME skeleton. Defaults to 10,\n",
    "                   but this is only from playing around and hasn't been thoroughly testted.\n",
    "    :return: coords: A dataframe with columns:\n",
    "                     x: x-pixel coords of the best estimate of the cme front\n",
    "                     y: y-pixel coords of the best estimate of the cme front\n",
    "                     pa:\n",
    "                     el:\n",
    "                     el_lo:\n",
    "                     el_hi:\n",
    "    \"\"\"\n",
    "    if pix_coords.shape[0] < 20:\n",
    "        print(\"Error: <20 coordinates provided, CME front identification likely to be poor\")\n",
    "\n",
    "    if kernel not in {\"gaussian\", \"tophat\", \"epanechnikov\", \"exponential\", \"linear\", \"cosine\"}:\n",
    "        print(\"Error: invalid kernel, defaulting to epanechnikov\")\n",
    "        kernel = \"epanechnikov\"\n",
    "\n",
    "    if not isinstance(bandwidth, (int, float)):\n",
    "        print(\"Error: bandwidth should be an int or float number. defaulting to 40\")\n",
    "        bandwidth = 40\n",
    "\n",
    "    if not isinstance(thresh, (int, float)):\n",
    "        print(\"Error: thresh should be an int or float number. defaulting to 10\")\n",
    "        bandwidth = 10\n",
    "\n",
    "    # Get all pixel coordinates in the image frame.\n",
    "    x = np.arange(0, 1024)\n",
    "    y = np.arange(0, 1024)\n",
    "    xm, ym = np.meshgrid(x, y)\n",
    "    # Get all coords for KSdensity\n",
    "    all_coords = np.vstack([xm.ravel(), ym.ravel()]).T\n",
    "    # Lookup HPR coords in frame\n",
    "    elm, pam = hip.convert_pix_to_hpr(xm * u.pix, ym * u.pix, hi_map)\n",
    "    # Loose the units as not needed\n",
    "    elm = elm.value\n",
    "    pam = pam.value\n",
    "\n",
    "    # Parse classification cloud to kernel density estimator. Returns log of density.\n",
    "    xy = np.vstack([pix_coords['x'].values.ravel(), pix_coords['y'].values.ravel()]).T\n",
    "    # Get flags for aborting the CME fit distributions\n",
    "    fit_distribution = True\n",
    "    fit_cme_distribution = True\n",
    "\n",
    "    if xy.shape[0] == 0:\n",
    "        fit_distribution = False\n",
    "\n",
    "    if fit_distribution:\n",
    "        # Use first stab at kernel density to\n",
    "        kde = KernelDensity(kernel=kernel, bandwidth=bandwidth).fit(xy)\n",
    "        log_pdf = np.reshape(kde.score_samples(all_coords), xm.shape)\n",
    "        # Convert the pdf to a binary map of where the distribution is > np.max(dist)/thresh\n",
    "        pdf = np.exp(log_pdf.copy())\n",
    "        \n",
    "        thresh = np.max(pdf) / thresh\n",
    "        pdf_binary = pdf.copy()\n",
    "        pdf_binary[pdf_binary < thresh] = 0\n",
    "        pdf_binary[pdf_binary >= thresh] = 1\n",
    "        # Only keep the largest CME feature in the binary map.\n",
    "        # Label each binary blob\n",
    "        pdf_binary_label = measure.label(pdf_binary.astype(int))\n",
    "        # update label so that the background pixels have the same label of zero\n",
    "        pdf_binary_label[pdf_binary == 0] = 0\n",
    "\n",
    "        # Find how many unique labels and how many pixels in each label\n",
    "        lab, cnt = np.unique(pdf_binary_label, return_counts=True)\n",
    "        # Sort these so largest is last in list.\n",
    "        # Largest should always be the background. So keep two largest - background and clearest CME identification\n",
    "        lab = lab[np.argsort(cnt)]\n",
    "        for l in lab[:-2]:\n",
    "            pdf_binary_label[pdf_binary_label == l] = 0\n",
    "\n",
    "        # Set the largest blob back to 1 rather than it's label.\n",
    "        pdf_binary_label[pdf_binary_label != 0] = 1\n",
    "\n",
    "        # Find classifications inside this polygon\n",
    "        id_keep = []\n",
    "        for idr, row in pix_coords.iterrows():\n",
    "            good_row = True\n",
    "            if (row['y'] < 0) | (row['y'] > 1023):\n",
    "                print \"row: {0}, y : {1}\".format(idr, row['y'])\n",
    "                good_row = False\n",
    "            if (row['x'] < 0) | (row['x'] > 1023):\n",
    "                print \"row: {0}, x : {1}\".format(idr, row['x'])\n",
    "                good_row = False\n",
    "\n",
    "            if good_row:\n",
    "                if pdf_binary_label[int(row['y']), int(row['x'])] == 1:\n",
    "                    id_keep.append(True)\n",
    "                else:\n",
    "                    id_keep.append(False)\n",
    "            else:\n",
    "                id_keep.append(False)\n",
    "\n",
    "        xy_in_cme = np.vstack([pix_coords['x'][id_keep].values.ravel(), pix_coords['y'][id_keep].values.ravel()]).T\n",
    "        hpr_in_cme = np.vstack([hpr_coords['pa'][id_keep].values.ravel(), hpr_coords['el'][id_keep].values.ravel()]).T\n",
    "\n",
    "        # Now fit only these points\n",
    "        # Are there any points left?\n",
    "        if xy_in_cme.shape[0] == 0:\n",
    "            fit_cme_distribution = False\n",
    "\n",
    "        if fit_cme_distribution:\n",
    "            kde = KernelDensity(kernel=kernel, bandwidth=bandwidth).fit(xy_in_cme)\n",
    "            log_pdf = np.reshape(kde.score_samples(all_coords), xm.shape)\n",
    "            cme_pdf = np.exp(log_pdf.copy())\n",
    "\n",
    "        # Use classifications to find range of PA values to look up CME elongation for.\n",
    "        # Preallocate space for CME front.\n",
    "        # Use ceil and floor so that pa_vals definitely stays in range.\n",
    "        # pa_vals = np.arange(np.ceil(hpr_in_cme[:,0].min()), np.floor(hpr_in_cme[:,0].max()), 1)\n",
    "        # cme_el_peak = np.zeros(pa_vals.shape)\n",
    "        # cme_el_lo = np.zeros(pa_vals.shape)\n",
    "        # cme_el_hi = np.zeros(pa_vals.shape)\n",
    "            # Loop over position angles, get FWHM of the kernel density estimate along constant PA.\n",
    "            # Use FWHM as elon error est.\n",
    "        #  for i, pa in enumerate(pa_vals):\n",
    "        #      # Get pixel coords of this PA slice\n",
    "        #      pa_slice = measure.find_contours(pam,pa)[0]\n",
    "        #      # Get values rounded to nearest pixel\n",
    "        #      pa_slice = pa_slice.astype(int)\n",
    "        #      pdf_pa = cme_pdf[pa_slice[:, 0], pa_slice[:, 1]]\n",
    "        #      el_pa = elm[pa_slice[:, 0], pa_slice[:, 1]]\n",
    "        #      cme_el_lo[i], cme_el_peak[i], cme_el_hi[i] = get_fwhm(el_pa, pdf_pa)\n",
    "\n",
    "    return pdf, pdf_binary, pdf_binary_label, xy_in_cme, cme_pdf, pam, elm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error, invalid path, check config: F:\\STEREO\\ares.nrl.navy.mil\\lz\n",
      "Error, invalid path, check config: F:\\STEREO\\ares.nrl.navy.mil\\lz\n",
      "8\n",
      "sta\n",
      "[MoviePy] >>>> Building video C:\\Users\\Luke\\PycharmProjects\\SolarStormwatchIIAnalysis\\figures\\process_animation\\ssw_processing_illustration.ogv\n",
      "[MoviePy] Writing video C:\\Users\\Luke\\PycharmProjects\\SolarStormwatchIIAnalysis\\figures\\process_animation\\ssw_processing_illustration.ogv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████████████████████████████████████▍| 70/71 [00:04<00:00, 15.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: C:\\Users\\Luke\\PycharmProjects\\SolarStormwatchIIAnalysis\\figures\\process_animation\\ssw_processing_illustration.ogv \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "A function to load in the test version of the HDF5 stormwatch data and produce a test plot.\n",
    ":return:\n",
    "\"\"\"\n",
    "\n",
    "project_dirs = ssw2.get_project_dirs()\n",
    "# Get the swpc cme database\n",
    "swpc_cmes = ssw2.load_swpc_events()\n",
    "\n",
    "# Import the SSW classifications data\n",
    "ssw_out_name = os.path.join(project_dirs['out_data'], 'all_classifications_matched_ssw_events_plus_HPR.hdf5')\n",
    "ssw_out = tables.open_file(ssw_out_name, mode=\"r\")\n",
    "\n",
    "# Make a directory to store all of these figures in\n",
    "fig_out_dir = os.path.join(project_dirs['figs'], \"process_animation\")\n",
    "if not os.path.exists(fig_out_dir):\n",
    "    os.mkdir(fig_out_dir)\n",
    "\n",
    "# Only do STA, EVENT 8, Differenced.\n",
    "\n",
    "# Iterate through the events, and annotate storm position on each plot.\n",
    "frame = 0\n",
    "\n",
    "def add_annotation(ax, label, box_col='k', txt_x=0.008, txt_y=0.975, txt_fs=18):\n",
    "    box = {'facecolor': box_col}\n",
    "    txt = ax.text(txt_x, txt_y, label,\n",
    "                  transform=ax.transAxes, fontsize=txt_fs, color='r', bbox=box)\n",
    "    return txt\n",
    "\n",
    "def save_frame(fig, frame, num_frames=1):\n",
    "    for i in range(num_frames):\n",
    "        out_name = \"frame_{:02d}.jpg\".format(frame)\n",
    "        out_path = os.path.join(fig_out_dir, out_name)\n",
    "        fig.subplots_adjust(left=0.01, bottom=0.01, right=0.99, top=0.99, wspace=0.02, hspace=0.02)\n",
    "        fig.savefig(out_path)\n",
    "        frame +=1\n",
    "        \n",
    "    return frame\n",
    "\n",
    "for event in ssw_out.iter_nodes('/'):\n",
    "\n",
    "    # Get ssw event number to loop up event HI start and stop time.\n",
    "    ssw_num = int(event._v_name.split('_')[1])\n",
    "\n",
    "    if ssw_num != 8:\n",
    "        continue\n",
    "\n",
    "    print ssw_num\n",
    "\n",
    "    for craft in event:\n",
    "\n",
    "\n",
    "        if craft._v_name != 'sta':\n",
    "            continue\n",
    "\n",
    "        print craft._v_name\n",
    "\n",
    "\n",
    "        t_start = swpc_cmes.loc[ssw_num, 't_hi1a_start']\n",
    "        t_stop = swpc_cmes.loc[ssw_num, 't_hi1a_stop']\n",
    "\n",
    "        hi_files = hip.find_hi_files(t_start, t_stop, craft=craft._v_name, camera='hi1', background_type=1)\n",
    "\n",
    "        fc = hi_files[1]\n",
    "        fp = hi_files[0]\n",
    "\n",
    "        for img_type in craft:\n",
    "\n",
    "            if img_type._v_name != 'diff':\n",
    "                continue\n",
    "\n",
    "            hi_map = hip.get_image_diff(fc, fp, align=True, smoothing=True)\n",
    "            normalise = mpl.colors.Normalize(vmin=-0.05, vmax=0.05)\n",
    "            img = mpl.cm.gray(normalise(hi_map.data), bytes=True)\n",
    "            \n",
    "            # Plot out the raw frame\n",
    "            fig, ax = plt.subplots(figsize=(10, 10))\n",
    "            ax.imshow(img, origin='lower')\n",
    "            ax.set_xlim(0, 1023)\n",
    "            ax.set_ylim(0, 1023)\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            txt = add_annotation(ax, \"STEREO-A HI1 Differenced image\")\n",
    "            frame = save_frame(fig, frame, num_frames=3)\n",
    "            \n",
    "            \n",
    "            fc_base = os.path.basename(fc)\n",
    "            time_label = \"T\"+ \"_\".join(fc_base.split('_')[0:2])\n",
    "            \n",
    "            # Get the time node for this file.\n",
    "            time = img_type._f_get_child(time_label)\n",
    "            \n",
    "            # Loop over users and add them on.\n",
    "            i=0\n",
    "            for user in time.users:\n",
    "                if i > len(colors)-1:\n",
    "                    i = 0\n",
    "                    \n",
    "                user_data = pd.DataFrame.from_records(user.coords.read())\n",
    "                user_data.replace(to_replace=[99999], value=np.NaN, inplace=True)\n",
    "                # Add on all classifications\n",
    "                ax.plot(user_data['x'], user_data['y'], 'o', markersize=mksz, color=colors[i])\n",
    "                # Update label\n",
    "                txt.set_text(\"Adding each citizen scientist classification\")\n",
    "                frame = save_frame(fig, frame)\n",
    "                i += 1\n",
    "                \n",
    "            # Overlay all the data           \n",
    "            all_data = pd.DataFrame.from_records(time.coords.read())\n",
    "            all_data.replace(to_replace=[99999], value=np.NaN, inplace=True)\n",
    "            # Add on all classifications as same color and save\n",
    "            ax.plot(all_data['x'], all_data['y'], 'o', markersize=mksz, color='y')\n",
    "            txt.set_text(\"All citizen scientist classifications\")\n",
    "            frame = save_frame(fig, frame, num_frames=3)\n",
    "                                  \n",
    "            # Now fit the kernal density distribution to this.\n",
    "            pix_coords = pd.DataFrame({'x': all_data['x'], 'y': all_data['y']})\n",
    "            hpr_coords = pd.DataFrame({'el': all_data['el'], 'pa': all_data['pa']})\n",
    "            pdf, pdf_binary, pdf_binary_label, xy_in_cme, cme_pdf, pam, elm = extract_cme_front_example(pix_coords, hpr_coords, hi_map, kernel=\"epanechnikov\", bandwidth=40, thresh=10)\n",
    "            \n",
    "            # Plot on the Kernel density estimate, and then the thresholded and segmented distributions\n",
    "            # Raw densities\n",
    "            ax.cla()\n",
    "            ax.imshow(pdf,cmap=mpl.cm.viridis, origin=\"lower\")\n",
    "            \n",
    "            ax.set_xlim(0, 1023)\n",
    "            ax.set_ylim(0, 1023)\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            add_annotation(ax,\"Density estimate of all classifications\")\n",
    "            frame = save_frame(fig, frame, num_frames=3)\n",
    "            \n",
    "            # Thresholded densities\n",
    "            ax.cla()\n",
    "            ax.imshow(pdf_binary, cmap='gray', origin=\"lower\")\n",
    "            ax.set_xlim(0, 1023)\n",
    "            ax.set_ylim(0, 1023)\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            add_annotation(ax,\"Thresholded density identifies largest features\")\n",
    "            frame = save_frame(fig, frame, num_frames=3)\n",
    "            \n",
    "            # Segmented densities\n",
    "            ax.cla()\n",
    "            ax.imshow(pdf_binary_label, cmap='gray', origin=\"lower\")\n",
    "            ax.set_xlim(0, 1023)\n",
    "            ax.set_ylim(0, 1023)\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            add_annotation(ax,\"Segmentation extracts the CME region\")\n",
    "            frame = save_frame(fig, frame, num_frames=3)\n",
    "            \n",
    "            # Remaining points\n",
    "            ax.cla()\n",
    "            ax.imshow(pdf_binary_label, cmap='gray', origin=\"lower\")\n",
    "            ax.plot(xy_in_cme[:,0], xy_in_cme[:,1], 'o', color='y', markersize=mksz)\n",
    "            ax.set_xlim(0, 1023)\n",
    "            ax.set_ylim(0, 1023)\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            add_annotation(ax,\"Classifications within the CME region\")\n",
    "            frame = save_frame(fig, frame, num_frames=3)\n",
    "            \n",
    "            # CME distribution\n",
    "            ax.cla()\n",
    "            ax.imshow(cme_pdf, cmap=mpl.cm.viridis, origin=\"lower\")\n",
    "            ax.set_xlim(0, 1023)\n",
    "            ax.set_ylim(0, 1023)\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            add_annotation(ax, \"Density estimate of classifications in CME region\")\n",
    "            frame = save_frame(fig, frame, num_frames=3)\n",
    "            \n",
    "            plt.close('all')\n",
    "            \n",
    "            fig, ax = plt.subplots(2,2,figsize=(10,10))\n",
    "            ax = ax.flatten()\n",
    "            ax_hi = ax[1]\n",
    "            ax_sub = [ax[0],ax[2],ax[3]]\n",
    "            ax_hi.imshow(cme_pdf, cmap=mpl.cm.viridis, origin=\"lower\")\n",
    "            ax_hi.set_xlim(0, 1023)\n",
    "            ax_hi.set_ylim(0, 1023)\n",
    "            ax_hi.get_xaxis().set_visible(False)\n",
    "            ax_hi.get_yaxis().set_visible(False)\n",
    "            txt = add_annotation(ax_hi,\"Calculate CME location along lines of fixed PA\", txt_x=-0.5, txt_y=0.975, txt_fs=18)\n",
    "\n",
    "            for a in ax_sub:\n",
    "                a.set_visible(False)\n",
    "\n",
    "            frame = save_frame(fig, frame, num_frames=3)\n",
    "            # Remove the annotation to make space for axis.\n",
    "            txt.remove()\n",
    "            \n",
    "            # Add on PA contour.\n",
    "            # Use classifications to find range of PA values to look up CME elongation for.\n",
    "            pa_vals = np.array([60,90,120])\n",
    "            cme_el_peak = np.zeros(pa_vals.shape)\n",
    "            cme_el_lo = np.zeros(pa_vals.shape)\n",
    "            cme_el_hi = np.zeros(pa_vals.shape)\n",
    "            # Loop over position angles, get FWHM of the kernel density estimate along constant PA.\n",
    "            for pa, a, col in zip(pa_vals, ax_sub, colors[3:8:2]):\n",
    "                # Get pixel coords of this PA slice\n",
    "                pa_slice = measure.find_contours(pam,pa)[0]\n",
    "                # Add on the PA contour\n",
    "                ax_hi.plot(pa_slice[:,1], pa_slice[:,0], '-', color=col, linewidth=3)\n",
    "\n",
    "                # Get values rounded to nearest pixel\n",
    "                pa_slice = pa_slice.astype(int)\n",
    "\n",
    "                pdf_pa = cme_pdf[pa_slice[:, 0], pa_slice[:, 1]]\n",
    "                el_pa = elm[pa_slice[:, 0], pa_slice[:, 1]]\n",
    "\n",
    "                a.set_visible(True)\n",
    "                a.plot(el_pa, pdf_pa,'-', color=col, linewidth=2)\n",
    "                a.set_xlabel('Elongation (degrees)', fontsize=14)\n",
    "                a.xaxis.set_label_coords(0.25, 0.075, transform=a.transAxes)\n",
    "                a.set_ylabel('Classification density', fontsize=14)\n",
    "                a.yaxis.set_label_coords(0.075, 0.5, transform=a.transAxes)\n",
    "\n",
    "                cme_el_lo, cme_el_peak, cme_el_hi = get_fwhm(el_pa, pdf_pa)\n",
    "                ymin, ymax = a.get_ylim()\n",
    "                a.vlines(cme_el_peak, ymin, ymax, linestyles=['-'], colors=['k'], linewidths=[2])\n",
    "                a.vlines([cme_el_lo, cme_el_hi], ymin, ymax, linestyles=['--'], colors=['k'], linewidths=[2])\n",
    "                a.set_xlim(5,20)\n",
    "\n",
    "                a.set_xticklabels([])\n",
    "                a.set_yticklabels([])\n",
    "                a.invert_xaxis()\n",
    "                frame = save_frame(fig, frame, num_frames=3)\n",
    "            plt.close('all')\n",
    "            \n",
    "            # Add on the CME front the the contour plot, then replace with the HI image\n",
    "            fig, ax = plt.subplots(figsize=(10,10))\n",
    "            ax.imshow(cme_pdf, cmap=mpl.cm.viridis, origin=\"lower\")\n",
    "            ax.set_xlim(0, 1023)\n",
    "            ax.set_ylim(0, 1023)\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            txt = add_annotation(ax,\"Repeat for all PA\")\n",
    "            frame = save_frame(fig, frame, num_frames=3)\n",
    "            txt.remove()\n",
    "            \n",
    "            # Add on all the position angle contours\n",
    "            levels = np.arange(np.int(pam.min()),np.int(pam.max()),1)\n",
    "            cnts = ax.contour(pam,levels=levels, colors=['r'], linewidths=[2])\n",
    "            frame = save_frame(fig, frame, num_frames=3)\n",
    "            \n",
    "            # Remove the contour lines, replace with CME front\n",
    "            for line in cnts.collections:\n",
    "                line.remove()\n",
    "            \n",
    "            \n",
    "            # Get the CME front.\n",
    "            cme = pd.DataFrame.from_records(time.cme_coords.read())\n",
    "            cme.replace(to_replace=[99999], value=np.NaN, inplace=True)\n",
    "            # Add on CME front and error\n",
    "            ax.plot(cme['x'], cme['y'], '-', color='r', linewidth=3 )\n",
    "            ax.plot(cme['x_lo'], cme['y_lo'], '--', color='r', linewidth=3)\n",
    "            ax.plot(cme['x_hi'], cme['y_hi'], '--', color='r', linewidth=3)\n",
    "            add_annotation(ax,\"The estimate of the CME front\")\n",
    "            frame = save_frame(fig, frame, num_frames=3)\n",
    "            \n",
    "            ax.cla()\n",
    "            ax.imshow(img, origin='lower')\n",
    "            ax.set_xlim(0, 1023)\n",
    "            ax.set_ylim(0, 1023)\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            \n",
    "            \n",
    "            # Get the CME front.\n",
    "            cme = pd.DataFrame.from_records(time.cme_coords.read())\n",
    "            cme.replace(to_replace=[99999], value=np.NaN, inplace=True)\n",
    "            # Add on CME front and error\n",
    "            ax.plot(cme['x'], cme['y'], '-', color='r', linewidth=3 )\n",
    "            ax.plot(cme['x_lo'], cme['y_lo'], '--', color='r', linewidth=3)\n",
    "            ax.plot(cme['x_hi'], cme['y_hi'], '--', color='r', linewidth=3)\n",
    "            add_annotation(ax,\"The estimate of the CME front\")\n",
    "            frame = save_frame(fig, frame, num_frames=3)\n",
    "            \n",
    "            # Now Loop through the differenced images to show how the tracking works.\n",
    "            files_current = hi_files[2:10]\n",
    "            files_previous = hi_files[1:9]\n",
    "            plt.close('all')\n",
    "            \n",
    "            for fc, fp in zip(files_current, files_previous):\n",
    "\n",
    "                hi_map = hip.get_image_diff(fc, fp, align=True, smoothing=True)\n",
    "                normalise = mpl.colors.Normalize(vmin=-0.05, vmax=0.05)\n",
    "                img = mpl.cm.gray(normalise(hi_map.data), bytes=True)\n",
    "\n",
    "                # Plot out the raw frame\n",
    "                fig, ax = plt.subplots(figsize=(10, 10))\n",
    "                ax.imshow(img, origin='lower')\n",
    "                ax.set_xlim(0, 1023)\n",
    "                ax.set_ylim(0, 1023)\n",
    "                ax.get_xaxis().set_visible(False)\n",
    "                ax.get_yaxis().set_visible(False)\n",
    "\n",
    "                fc_base = os.path.basename(fc)\n",
    "                time_label = \"T\"+ \"_\".join(fc_base.split('_')[0:2])\n",
    "\n",
    "                # Get the time node for this file.\n",
    "                time = img_type._f_get_child(time_label)\n",
    "                \n",
    "                cme = pd.DataFrame.from_records(time.cme_coords.read())\n",
    "                cme.replace(to_replace=[99999], value=np.NaN, inplace=True)\n",
    "                # Add on CME front and error\n",
    "                ax.plot(cme['x'], cme['y'], '-', color='r', linewidth=3 )\n",
    "                ax.plot(cme['x_lo'], cme['y_lo'], '--', color='r', linewidth=3)\n",
    "                ax.plot(cme['x_hi'], cme['y_hi'], '--', color='r', linewidth=3)\n",
    "                add_annotation(ax,\"Repeat for later frames\")\n",
    "                frame = save_frame(fig, frame)\n",
    "                plt.close('all')\n",
    "\n",
    "\n",
    "src = os.path.join(fig_out_dir, '*.jpg')            \n",
    "dst = os.path.join(fig_out_dir, 'ssw_processing_illustration.ogv')\n",
    "make_ogv(src, dst, tidy=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
